{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìä Dataset Maker by Hollowstrawberry\n",
        "\n",
        "Here is a [guide to using this colab](https://civitai.com/models/22530). It will help you make a dataset quickly and using it to train a Lora.\n",
        "\n",
        "This is based on the work of [Kohya-ss and Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb#scrollTo=-Z4w3lfFKLjr). Image curation adapted from [this other colab](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7#scrollTo=fl4E_J5g2grT). Thank you!"
      ],
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Colab|English|Spanish|\n",
        "|:--|:-:|:-:|\n",
        "| üìä **Dataset Maker** | <a target=\"_blank\" href=\"https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a> | [üá™üá∏](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | <a target=\"_blank\" href=\"https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb\"> <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a> | [üá™üá∏](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |"
      ],
      "metadata": {
        "id": "-rdgF2AWLS2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## üö© Start Here\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown ### 1Ô∏è‚É£ Setup\n",
        "#@markdown This cell will connect to your Google Drive and create the necessary folders under `lora_training`. <p>\n",
        "#@markdown Your project name will be the same as the folder containing your images. Spaces aren't allowed.\n",
        "project_name = \"\" #@param {type:\"string\"}\n",
        "project_name = project_name.strip()\n",
        "\n",
        "if not project_name or \" \" in project_name:\n",
        "  print(\"Please write a valid project_name.\")\n",
        "else:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  #root_dir\n",
        "  root_dir = \"/content\"\n",
        "  deps_dir = os.path.join(root_dir,\"deps\")\n",
        "  main_dir = os.path.join(root_dir,\"drive/MyDrive/lora_training\")\n",
        "  datasets_dir = os.path.join(main_dir,\"datasets\")\n",
        "  config_dir = os.path.join(main_dir,\"config\")\n",
        "  images_folder = os.path.join(datasets_dir, project_name)\n",
        "  config_folder = os.path.join(config_dir, project_name)\n",
        "\n",
        "  for dir in [deps_dir, main_dir, datasets_dir, config_dir, images_folder, config_folder]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  print(f\"‚úÖ Project {project_name} is ready!\")"
      ],
      "metadata": {
        "id": "cBa7KdewQ4BU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 2Ô∏è‚É£ Scrape images from Gelbooru\n",
        "\n",
        "import os\n",
        "import html\n",
        "import json\n",
        "import time\n",
        "from urllib.request import urlopen, Request\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import output as console\n",
        "\n",
        "#@markdown We will grab images from the popular anime gallery [Gelbooru](https://gelbooru.com/). Images are sorted by tags, including poses, scenes, character traits, character names, artists, etc. <p>\n",
        "#@markdown * If you instead want to use your own images, upload them to your Google Drive's `lora_training/datasets/project_name` folder.\n",
        "#@markdown * If you instead want to download screencaps of anime episodes, try [this other colab by another person](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7). It's more complicated though.\n",
        "\n",
        "#@markdown Up to 1000 images may be downloaded by this step in just one minute. Don't abuse it. <p>\n",
        "#@markdown Your target tags should probably include a minimum score, exclude explicit images (they often make training harder) and include the relevant tags for your character/concept/artstyle.\n",
        "#@markdown Separate words with underscores, separate tags with spaces, and use - to exclude a tag.\n",
        "tags = \"score:>10 -rating:explicit -loli -futanari -monochrome 1girl solo rem_(re:zero)\" #@param {type:\"string\"}\n",
        "##@markdown If an image is bigger than this resolution a smaller version will be downloaded instead.\n",
        "max_resolution = 2048 #param {type:\"slider\", min:2048, max:8196, step:2048}\n",
        "##@markdown Posts with a parent post are often minor variations of the same image.\n",
        "include_posts_with_parent = True #param {type:\"boolean\"}\n",
        "\n",
        "tags = tags.replace(\" \", \"+\")\\\n",
        "           .replace(\"(\", \"%28\")\\\n",
        "           .replace(\")\", \"%29\")\\\n",
        "           .replace(\":\", \"%3a\")\\\n",
        "          \n",
        "url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
        "user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
        "limit = 100 # hardcoded by gelbooru\n",
        "total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "  print(\"üè≠ Installing dependencies...\")\n",
        "  !wget -q --show-progress {url}\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  with zipfile.ZipFile(name, 'r') as deps:\n",
        "    deps.extractall(dst)\n",
        "  !dpkg -i {dst}/*\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  os.remove(name)\n",
        "  shutil.rmtree(dst)\n",
        "  console.clear()\n",
        "  return True\n",
        "\n",
        "if \"step2_installed_flag\" not in globals():\n",
        "  if ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\", \"deb-libs.zip\", deps_dir):\n",
        "    step2_installed_flag = True\n",
        "\n",
        "def get_json(url):\n",
        "  with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
        "    return json.load(page)\n",
        "\n",
        "def filter_images(data):\n",
        "  return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
        "          for p in data[\"post\"]\n",
        "          if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
        "          and p[\"file_url\"].endswith(supported_types)]\n",
        "\n",
        "def download_images():\n",
        "  data = get_json(url)\n",
        "  count = data[\"@attributes\"][\"count\"]\n",
        "\n",
        "  if count == 0:\n",
        "    print(\"üì∑ No images found\")\n",
        "    return\n",
        "\n",
        "  print(f\"üéØ Found {count} images\")\n",
        "  test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "  display(Markdown(f\"[Click here to open in browser!]({test_url})\"))\n",
        "  inp = input(\"‚ùì Enter the word 'yes' if you want to proceed with the download: \")\n",
        "\n",
        "  if inp.lower().strip() != 'yes':\n",
        "    print(\"‚ùå Download cancelled\")\n",
        "    return\n",
        "\n",
        "  print(\"üì© Grabbing image list...\")\n",
        "\n",
        "  image_urls = set()\n",
        "  image_urls = image_urls.union(filter_images(data))\n",
        "  for i in range(total_limit // limit):\n",
        "    count -= limit\n",
        "    if count <= 0:\n",
        "      break\n",
        "    time.sleep(0.1)\n",
        "    image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
        "\n",
        "  scrape_file = os.path.join(config_folder, f\"scraped_links.txt\")\n",
        "  with open(scrape_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(image_urls))\n",
        "\n",
        "  print(f\"üåê Saved links to {scrape_file}\\nüîÅ Starting download to {images_folder} ...\\n\")\n",
        "  old_img_count = len([f for f in os.listdir(images_folder) if f.endswith(supported_types)])\n",
        "\n",
        "  os.chdir(images_folder)\n",
        "  !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scrape_file}\n",
        "\n",
        "  new_img_count = len([f for f in os.listdir(images_folder) if f.endswith(supported_types)])\n",
        "  print(f\"\\n‚úÖ Downloaded {new_img_count - old_img_count} images.\")\n",
        "\n",
        "download_images()\n"
      ],
      "metadata": {
        "id": "afu5dCKTV31E",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 3Ô∏è‚É£ Curate your images\n",
        "#@markdown We will find duplicate images with the FiftyOne AI, and mark them with `delete`. <p>\n",
        "#@markdown Then, an interactive area will appear below this cell that lets you visualize all your images and manually mark with `delete` to the ones you don't like. <p>\n",
        "#@markdown If the interactive area appears blank for over a minute, try enabling cookies and removing tracking protection for the Google Colab website, as they may break it.\n",
        "#@markdown Regardless, you can save your changes by sending Enter in the input box above the interactive area.<p>\n",
        "#@markdown This is how similar 2 images must be to be marked for deletion. I recommend 0.97 to 0.99:\n",
        "similarity_threshold = 0.985 #@param {type:\"number\"}\n",
        "\n",
        "import os\n",
        "from google.colab import output as console\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "model_name = \"clip-vit-base32-torch\"\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "img_count = len(os.listdir(images_folder))\n",
        "batch_size = min(250, img_count)\n",
        "\n",
        "if \"step3_installed_flag\" not in globals():\n",
        "  print(\"üè≠ Installing dependencies...\\n\")\n",
        "  !pip install fiftyone ftfy\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    console.clear()\n",
        "    step3_installed_flag = True\n",
        "\n",
        "import numpy as np\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "non_images = [f for f in os.listdir(images_folder) if not f.endswith(supported_types)]\n",
        "if non_images:\n",
        "  print(f\"üí• Error: Found non-image file {non_images[0]} - This program doesn't allow it. Sorry!\")\n",
        "elif img_count == 0:\n",
        "  print(f\"üí• Error: No images found in {images_folder}\")\n",
        "else:\n",
        "  print(\"üíø Analyzing dataset...\\n\")\n",
        "  dataset = fo.Dataset.from_dir(images_folder, dataset_type=fo.types.ImageDirectory)\n",
        "  model = foz.load_zoo_model(model_name)\n",
        "  embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "  batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "  similarity_matrices = []\n",
        "  max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "  max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "  for i, batch_embedding in enumerate(batch_embeddings):\n",
        "    similarity = cosine_similarity(batch_embedding)\n",
        "    #Pad 0 for np.concatenate\n",
        "    padded_array = np.zeros((max_size_x, max_size_y))\n",
        "    padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "    similarity_matrices.append(padded_array)\n",
        "\n",
        "  similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "  similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "  similarity_matrix = cosine_similarity(embeddings)\n",
        "  similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "  dataset.match(F(\"max_similarity\") > similarity_threshold)\n",
        "  dataset.tags = [\"delete\", \"has_duplicates\"]\n",
        "\n",
        "  id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "  samples_to_remove = set()\n",
        "  samples_to_keep = set()\n",
        "\n",
        "  for idx, sample in enumerate(dataset):\n",
        "    if sample.id not in samples_to_remove:\n",
        "      # Keep the first instance of two duplicates\n",
        "      samples_to_keep.add(sample.id)\n",
        "      \n",
        "      dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]\n",
        "      for dup in dup_idxs:\n",
        "          # We kept the first instance so remove all other duplicates\n",
        "          samples_to_remove.add(id_map[dup])\n",
        "\n",
        "      if len(dup_idxs) > 0:\n",
        "          sample.tags.append(\"has_duplicates\")\n",
        "          sample.save()\n",
        "    else:\n",
        "      sample.tags.append(\"delete\")\n",
        "      sample.save()\n",
        "\n",
        "  console.clear()\n",
        "\n",
        "  sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
        "  for group in sidebar_groups[2:]:\n",
        "    group.expanded = False\n",
        "  dataset.app_config.sidebar_groups = sidebar_groups\n",
        "  dataset.save()\n",
        "  session = fo.launch_app(dataset)\n",
        "\n",
        "  print(\"‚ùó Wait a minute for the session to load. If it doesn't, read above.\")\n",
        "  print(\"‚ùó When it's ready, you'll see a grid of your images.\")\n",
        "  print(\"‚ùó On the left side enable the \\\"delete\\\" label to visualize the images marked for deletion.\")\n",
        "  print(\"‚ùó You can mark your own images with the \\\"delete\\\" label by selecting them and pressing the tag icon at the top.\")\n",
        "  input(\"‚≠ï When you're done, enter something here to save your changes: \")\n",
        "\n",
        "  session.refresh()\n",
        "  fo.close_app()\n",
        "  console.clear()\n",
        "  print(\"üíæ Saving...\")\n",
        "\n",
        "  kys = [s for s in dataset if \"delete\" in s.tags]\n",
        "  dataset.remove_samples(kys)\n",
        "  dataset.export(export_dir=os.path.join(images_folder, project_name), dataset_type=fo.types.ImageDirectory)\n",
        "  \n",
        "  temp_suffix = \"_temp\"\n",
        "  !mv {images_folder} {images_folder}{temp_suffix}\n",
        "  !mv {images_folder}{temp_suffix}/{project_name} {datasets_dir}\n",
        "  !rm -r {images_folder}{temp_suffix}\n",
        "\n",
        "  print(f\"\\n‚úÖ Removed {len(kys)} images from dataset. You now have {len(os.listdir(images_folder))} images.\")\n"
      ],
      "metadata": {
        "id": "b218DEEMpwzB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 4Ô∏è‚É£ Tag your images\n",
        "#@markdown We will be using AI to automatically tag your images, specifically [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2) in the case of anime and [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) in the case of photoealism.\n",
        "#@markdown Giving tags/captions to your images allows for much better training. This process should take a couple minutes. <p>\n",
        "method = \"Photorealism captions\" #@param [\"Anime tags\", \"Photorealism captions\"]\n",
        "#@markdown **Anime:** The threshold is the minimum level of confidence the tagger must have in order to include a tag. Lower threshold = More tags\n",
        "tag_threshold = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "#@markdown **Photorealism:** The minimum and maximum length of tokens/words in each caption.\n",
        "caption_min = 10 #@param {type:\"number\"}\n",
        "caption_max = 75 #@param {type:\"number\"}\n",
        "\n",
        "%env PYTHONPATH=/env/python\n",
        "import os\n",
        "from google.colab import output as console\n",
        "from IPython import get_ipython\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "kohya = \"/content/kohya-trainer\"\n",
        "if not os.path.exists(kohya):\n",
        "  !git clone https://github.com/Linaqruf/kohya-trainer {kohya}\n",
        "  os.chdir(kohya)\n",
        "  !git reset --hard 86de685a8c37e60a610d08cbece3da6b3a553bc0\n",
        "  os.chdir(\"/content\")\n",
        "\n",
        "if \"tags\" in method:\n",
        "  if \"step4a_installed_flag\" not in globals():\n",
        "    print(\"\\nüè≠ Installing dependencies...\\n\")\n",
        "    !pip install tensorflow==2.10.1 huggingface-hub==0.12.0 accelerate==0.15.0 transformers==4.26.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      console.clear()\n",
        "      step4a_installed_flag = True\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
        "\n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/tag_images_by_wd14_tagger.py \\\n",
        "    {images_folder} \\\n",
        "    --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 \\\n",
        "    --model_dir=/content \\\n",
        "    --thresh={tag_threshold} \\\n",
        "    --batch_size=8 \\\n",
        "    --caption_extension=.txt \\\n",
        "    --force_download\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    print(\"removing underscores...\")\n",
        "    from collections import Counter\n",
        "    top_tags = Counter()\n",
        "    for txt in [f for f in os.listdir(images_folder) if f.endswith(\".txt\")]:\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        tags = [t.strip() for t in f.read().split(\",\")]\n",
        "        tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
        "      top_tags.update(tags)\n",
        "      with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "        f.write(\", \".join(tags))\n",
        "\n",
        "    %env PYTHONPATH=/env/python\n",
        "    console.clear()\n",
        "    print(f\"üìä Tagging complete. Here are the top 50 tags in your dataset:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "\n",
        "    \n",
        "else: # Photorealism\n",
        "  if \"step4b_installed_flag\" not in globals():\n",
        "    print(\"\\nüè≠ Installing dependencies...\\n\")\n",
        "    !pip install timm==0.6.12 fairscale==0.4.13 transformers==4.26.0 requests==2.28.2 accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      console.clear()\n",
        "      step4b_installed_flag = True\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n",
        "\n",
        "  os.chdir(kohya)\n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/make_captions.py \\\n",
        "    {images_folder} \\\n",
        "    --beam_search \\\n",
        "    --max_data_loader_n_workers=2 \\\n",
        "    --batch_size=8 \\\n",
        "    --min_length={caption_min} \\\n",
        "    --max_length={caption_max} \\\n",
        "    --caption_extension=.txt\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    import random\n",
        "    captions = [f for f in os.listdir(images_folder) if f.endswith(\".txt\")]\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "    %env PYTHONPATH=/env/python\n",
        "    console.clear()\n",
        "    print(f\"üìä Captioning complete. Here are {len(sample)} example captions from your dataset:\")\n",
        "    print(\"\".join(sample))\n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sl4FD7Mz-uea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#@markdown ### 5Ô∏è‚É£ Curate your tags\n",
        "#@markdown Modify your dataset's tags. You can run this cell multiple times with different parameters. <p>\n",
        "\n",
        "#@markdown Put an activation tag at the start of every text file. This is useful to make learning better and activate your Lora easier. Set `keep_tokens` to 1 when training.<p>\n",
        "#@markdown Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.\n",
        "global_activation_tag = \"\" #@param {type:\"string\"}\n",
        "remove_tags = \"\" #@param {type:\"string\"}\n",
        "#@markdown &nbsp;\n",
        "\n",
        "#@markdown In this advanced section, you can search text files containing matching tags, and replace them with less/more/different tags. If you select the checkbox below, any extra tags will be put at the start of the file, letting you assign different activation tags to different parts of your dataset. Still, you may want a more advanced tool for this.\n",
        "search_tags = \"\" #@param {type:\"string\"}\n",
        "replace_with = \"\" #@param {type:\"string\"}\n",
        "search_mode = \"OR\" #@param [\"OR\", \"AND\"]\n",
        "new_becomes_activation_tag = False #@param {type:\"boolean\"}\n",
        "#@markdown These may be useful sometimes. Will remove existing activation tags, be careful.\n",
        "sort_alphabetically = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = False #@param {type:\"boolean\"}\n",
        "\n",
        "def split_tags(tagstr):\n",
        "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "for txt in [f for f in os.listdir(images_folder) if f.endswith(\".txt\")]:\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "  if remove_duplicates:\n",
        "    tags = list(set(tags))\n",
        "  if sort_alphabetically:\n",
        "    tags.sort()\n",
        "\n",
        "  for rem in remove_tags_list:\n",
        "    if rem in tags:\n",
        "      remove_count += 1\n",
        "      tags.remove(rem)\n",
        "\n",
        "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
        "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
        "    replace_count += 1\n",
        "    for rem in search_tags_list:\n",
        "      if rem in tags:\n",
        "        tags.remove(rem)\n",
        "    for add in replace_with_list:\n",
        "      if add not in tags:\n",
        "        tags.append(add)\n",
        "    for new in replace_new_list:\n",
        "      if new_becomes_activation_tag:\n",
        "        if new in tags:\n",
        "          tags.remove(new)\n",
        "        tags.insert(0, new)\n",
        "      else:\n",
        "        if new not in tags:\n",
        "          tags.append(new)\n",
        "\n",
        "  for act in activation_tag_list:\n",
        "    if act in tags:\n",
        "      tags.remove(act)\n",
        "    tags.insert(0, act)\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "    f.write(\", \".join(tags))\n",
        "\n",
        "if remove_tags:\n",
        "  print(f\"\\nüöÆ Removed {remove_count} tags.\")\n",
        "if search_tags:\n",
        "  print(f\"\\nüí´ Replaced in {replace_count} files.\")\n",
        "print(\"\\n‚úÖ Done!\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WBFik7accyDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### 6Ô∏è‚É£ Ready\n",
        "#@markdown You should be ready to [train your Lora](https://colab.research.google.com/drive/1fs7oHytA4Va0IzDK-F8q_q9RIJRIh5Dv?usp=sharing)!\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"### ü¶Ä [Click here to open the Lora trainer](https://colab.research.google.com/drive/1fs7oHytA4Va0IzDK-F8q_q9RIJRIh5Dv?usp=sharing)\"))\n"
      ],
      "metadata": {
        "id": "HuJB7BGAyZCw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Ô∏è‚É£ Extras"
      ],
      "metadata": {
        "id": "gDB9GXRONfiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìà Analyze Tags\n",
        "#@markdown Perhaps you need another look at your dataset.\n",
        "show_top_tags = 200 #@param {type:\"number\"}\n",
        "\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(images_folder) if f.endswith(\".txt\")]:\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"üìä Top {show_top_tags} tags:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xEsqOglcc6hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üìÇ Unzip dataset\n",
        "#@markdown It's much slower to upload individual files to your Drive, so you may want to upload a zip if you have your dataset in your computer.\n",
        "zip = \"/content/drive/MyDrive/lora_training/datasets/example.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/lora_training/datasets/example/\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "x56xQYwuOz2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### üî¢ Count datasets\n",
        "#@markdown Google Drive makes it impossible to count the files in a folder, so this will show you the file counts in all folders and subfolders.\n",
        "folder = \"/content/drive/MyDrive/lora_training/datasets\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder)):\n",
        "  images = len([f for f in files if f.endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images and not captions and not others \\\n",
        "                    else f\"{images:>4} images | {captions:>4} text files | {others:>4} other files\"\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dLetTcLVOvAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
