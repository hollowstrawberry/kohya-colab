{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# üìä Preparador de Lora de Hollowstrawberry\n",
        "\n",
        "Este colab viene de [esta gu√≠a](https://huggingface.co/hollowstrawberry/stable-diffusion-guide/blob/main/README.md#index). Te permitir√° obtener tus im√°genes y tags para entrenar Loras.\n",
        "\n",
        "Basado en el trabajo de [Kohya_ss y Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb#scrollTo=-Z4w3lfFKLjr). ¬°Gracias!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0BJTp5PVN_q-"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cBa7KdewQ4BU"
      },
      "outputs": [],
      "source": [
        "#@title ## üö© Empezar aqu√≠\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown ### 1Ô∏è‚É£  Inicio\n",
        "#@markdown Esta celda se conectar√° a tu Google Drive y crear√° las carpetas necesarias dentro de `lora_training`. <p>\n",
        "#@markdown Tu nombre de proyecto ser√° la carpeta donde trabajaremos. No se permiten espacios.\n",
        "nombre_proyecto = \"\" #@param {type:\"string\"}\n",
        "project_name = nombre_proyecto.strip()\n",
        "\n",
        "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\"):\n",
        "  print(\"Por favor elige un nombre v√°lido.\")\n",
        "else:\n",
        "  if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Conectando a Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  #root_dir\n",
        "  root_dir = \"/content\"\n",
        "  deps_dir = os.path.join(root_dir,\"deps\")\n",
        "  main_dir = os.path.join(root_dir,\"drive/MyDrive/lora_training\")\n",
        "  datasets_dir = os.path.join(main_dir,\"datasets\")\n",
        "  config_dir = os.path.join(main_dir,\"config\")\n",
        "  images_folder = os.path.join(datasets_dir, project_name)\n",
        "  config_folder = os.path.join(config_dir, project_name)\n",
        "\n",
        "  for dir in [deps_dir, main_dir, datasets_dir, config_dir, images_folder, config_folder]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  print(f\"‚úÖ ¬°Proyecto {project_name} listo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "afu5dCKTV31E"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 2Ô∏è‚É£ Obtener im√°genes\n",
        "\n",
        "import os\n",
        "import html\n",
        "import json\n",
        "import time\n",
        "from urllib.request import urlopen, Request\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import output as console\n",
        "\n",
        "#@markdown Obtendremos im√°genes de la galer√≠a de anime llamada [Gelbooru](https://gelbooru.com/). Las im√°genes se organizan por miles de tags que describen todo acerca de una imagen. <p>\n",
        "#@markdown * Si quieres encontrar y usar tus propias im√°genes, ponlas dentro de la carpeta `lora_training/datasets/nombre_proyecto` en tu Google Drive.\n",
        "#@markdown * Si quieres descargar capturas de episodios de anime, existe [este otro colab de otra persona](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7) aunque aquel es m√°s complicado.\n",
        "\n",
        "#@markdown Hasta 1000 im√°genes se descargar√°n en un minuto, no debes abusar de ello. <p>\n",
        "#@markdown Tus tags deben ser relevantes para lo que desees entrenar, y recomiendo incluir una puntuaci√≥n m√≠nima (score) y excluir la calificaci√≥n expl√≠cita (puede hacer m√°s dif√≠cil el entrenamiento).\n",
        "#@markdown Las palabras van separadas por guionbajos, las tags van separadas por espacios, y usa - para excluir esa tag de tus resultados.\n",
        "tags = \"score:>10 -rating:explicit -loli -futanari -monochrome 1girl solo rem_(re:zero)\" #@param {type:\"string\"}\n",
        "##@markdown If an image is bigger than this resolution a smaller version will be downloaded instead.\n",
        "max_resolution = 2048 #param {type:\"slider\", min:2048, max:8196, step:2048}\n",
        "##@markdown Posts with a parent post are often minor variations of the same image.\n",
        "include_posts_with_parent = True #param {type:\"boolean\"}\n",
        "\n",
        "tags = tags.replace(\" \", \"+\")\\\n",
        "           .replace(\"(\", \"%28\")\\\n",
        "           .replace(\")\", \"%29\")\\\n",
        "           .replace(\":\", \"%3a\")\\\n",
        "          \n",
        "url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
        "user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
        "limit = 100 # hardcoded by gelbooru\n",
        "total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "def ubuntu_deps(url, name, dst):\n",
        "  print(\"üè≠ Instalando...\")\n",
        "  !wget -q --show-progress {url}\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  with zipfile.ZipFile(name, 'r') as deps:\n",
        "    deps.extractall(dst)\n",
        "  !dpkg -i {dst}/*\n",
        "  if get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    return\n",
        "  os.remove(name)\n",
        "  shutil.rmtree(dst)\n",
        "  console.clear()\n",
        "  return True\n",
        "\n",
        "if \"step2_installed_flag\" not in globals():\n",
        "  if ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\", \"deb-libs.zip\", deps_dir):\n",
        "    step2_installed_flag = True\n",
        "\n",
        "def get_json(url):\n",
        "  with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
        "    return json.load(page)\n",
        "\n",
        "def filter_images(data):\n",
        "  return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
        "          for p in data[\"post\"]\n",
        "          if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
        "          and p[\"file_url\"].lower().endswith(supported_types)]\n",
        "\n",
        "def download_images():\n",
        "  data = get_json(url)\n",
        "  count = data[\"@attributes\"][\"count\"]\n",
        "\n",
        "  if count == 0:\n",
        "    print(\"üì∑ No se encontraron resultados.\")\n",
        "    return\n",
        "\n",
        "  print(f\"üéØ Se encontraron {count} resultados\")\n",
        "  test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "  display(Markdown(f\"[¬°Click aqu√≠ para verlos en tu navegador!]({test_url})\"))\n",
        "  inp = input(\"‚ùì Escribe \\\"si\\\" para continuar con la descarga: \")\n",
        "\n",
        "  if inp.lower().strip() not in (\"si\", \"s√≠\"):\n",
        "    print(\"‚ùå Download cancelled\")\n",
        "    return\n",
        "\n",
        "  print(\"üì© Obteniendo lista de im√°genes...\")\n",
        "\n",
        "  image_urls = set()\n",
        "  image_urls = image_urls.union(filter_images(data))\n",
        "  for i in range(total_limit // limit):\n",
        "    count -= limit\n",
        "    if count <= 0:\n",
        "      break\n",
        "    time.sleep(0.1)\n",
        "    image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
        "\n",
        "  scrape_file = os.path.join(config_folder, f\"scraped_links.txt\")\n",
        "  with open(scrape_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(image_urls))\n",
        "\n",
        "  print(f\"üåê Enlaces guardados a {scrape_file}\\nüîÅ Empezando descarga en {images_folder} ...\\n\")\n",
        "  old_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "\n",
        "  os.chdir(images_folder)\n",
        "  !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scrape_file}\n",
        "\n",
        "  new_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "  print(f\"\\n‚úÖ Se han descargado {new_img_count - old_img_count} im√°genes.\")\n",
        "\n",
        "download_images()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b218DEEMpwzB"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 3Ô∏è‚É£ Filtra tus im√°genes\n",
        "#@markdown Vamos a analizar y encontrar im√°genes duplicadas usando la IA de FiftyOne, y las marcaremos con `eliminar`. <p>\n",
        "#@markdown Cuando termine este proceso de varios minutos, aparecer√° una zona interactiva bajo esta celda que te permitir√° ver todas tus im√°genes y marcar las que no te gusten con `eliminar` ttambi√©n. <p>\n",
        "#@markdown Si el √°rea interactiva no carga despu√©s de un minuto, intenta activar las cookies o desactivar la protecci√≥n del navegador para la p√°gina de Google Colab, ya que estos pueden interferir. <p>\n",
        "#@markdown En cualquier caso, cuando est√©s satisfecho puedes mandar Enter en la casilla de texto arriba de la zona interactiva para finalizar y guardar los cambios.\n",
        "#@markdown <p>&nbsp;<p>Qu√© tan similares deben ser dos im√°genes para ser consideradas duplicadas. Recomiendo 0.97 a 0.99.\n",
        "similarity_threshold = 0.985 #@param {type:\"number\"}\n",
        "\n",
        "import os\n",
        "from google.colab import output as console\n",
        "\n",
        "model_name = \"clip-vit-base32-torch\"\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "img_count = len(os.listdir(train_data_dir))\n",
        "batch_size = min(250, img_count)\n",
        "\n",
        "if \"step3_installed_flag\" not in globals():\n",
        "  print(\"üè≠ Instalando...\\n\")\n",
        "  !pip install fiftyone ftfy\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    console.clear()\n",
        "    step3_installed_flag = True\n",
        "\n",
        "import numpy as np\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "non_images = [f for f in os.listdir(train_data_dir) if not f.lower().endswith(supported_types)]\n",
        "if non_images:\n",
        "  print(f\"üí• Error: El archivo {non_images[0]} no es una imagen. Este programa no puede correr con otros archivos de por medio, lo lamento. Puedes usar los Extras para limpiar la carpeta.\")\n",
        "elif img_count == 0:\n",
        "  print(f\"üí• Error: No hay im√°genes en {train_data_dir}\")\n",
        "else:\n",
        "  print(\"üíø Analizando im√°genes...\")\n",
        "  dataset = fo.Dataset.from_dir(train_data_dir, dataset_type=fo.types.ImageDirectory)\n",
        "  model = foz.load_zoo_model(model_name)\n",
        "  embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "  batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "  similarity_matrices = []\n",
        "  max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "  max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "  for i, batch_embedding in enumerate(batch_embeddings):\n",
        "      similarity = cosine_similarity(batch_embedding)\n",
        "      #Pad 0 for np.concatenate\n",
        "      padded_array = np.zeros((max_size_x, max_size_y))\n",
        "      padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "      similarity_matrices.append(padded_array)\n",
        "\n",
        "  similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "  similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "  similarity_matrix = cosine_similarity(embeddings)\n",
        "  similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "  dataset.match(F(\"max_similarity\") > similarity_threshold)\n",
        "  dataset.tags = [\"eliminar\", \"tiene_duplicados\"]\n",
        "\n",
        "  id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "  samples_to_remove = set()\n",
        "  samples_to_keep = set()\n",
        "\n",
        "  for idx, sample in enumerate(dataset):\n",
        "      if sample.id not in samples_to_remove:\n",
        "          # Keep the first instance of two duplicates\n",
        "          samples_to_keep.add(sample.id)\n",
        "          \n",
        "          dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]\n",
        "          for dup in dup_idxs:\n",
        "              # We kept the first instance so remove all other duplicates\n",
        "              samples_to_remove.add(id_map[dup])\n",
        "\n",
        "          if len(dup_idxs) > 0:\n",
        "              sample.tags.append(\"tiene_duplicados\")\n",
        "              sample.save()\n",
        "      else:\n",
        "          sample.tags.append(\"eliminar\")\n",
        "          sample.save()\n",
        "\n",
        "  console.clear()\n",
        "\n",
        "  sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
        "  for group in sidebar_groups[2:]:\n",
        "    group.expanded = False\n",
        "  dataset.app_config.sidebar_groups = sidebar_groups\n",
        "  dataset.save()\n",
        "  session = fo.launch_app(dataset)\n",
        "\n",
        "  print(\"‚ùó Espera un minuto mientras carga la zona interactiva. Si no carga lee arriba.\")\n",
        "  print(\"‚ùó Cuando est√© listo ver√°s una cuadr√≠cula con tus im√°genes.\")\n",
        "  print(\"‚ùó Al lado izquierdo selecciona la etiqueta \\\"eliminar\\\" para ver cu√°les im√°genes ser√°n borradas.\")\n",
        "  print(\"‚ùó Puedes marcar tus propias im√°genes no deseadas con \\\"eliminar\\\" al seleccionarlas y luego apretar el √≠cono de etiqueta en la parte de arriba.\")\n",
        "  input(\"‚≠ï Cuando termines, manda Enter aqu√≠ para guardar los cambios: \")\n",
        "\n",
        "  session.refresh()\n",
        "  fo.close_app()\n",
        "  console.clear()\n",
        "  print(\"üíæ Guardando...\")\n",
        "\n",
        "  kys = [s for s in dataset if \"eliminar\" in s.tags]\n",
        "  dataset.remove_samples(kys)\n",
        "  real_project_name = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n",
        "  previous_folder = images_folder[:images_folder.rfind(\"/\")]\n",
        "  dataset.export(export_dir=os.path.join(images_folder, real_project_name), dataset_type=fo.types.ImageDirectory)\n",
        "  \n",
        "  temp_suffix = \"_temp\"\n",
        "  !mv {images_folder} {images_folder}{temp_suffix}\n",
        "  !mv {images_folder}{temp_suffix}/{real_project_name} {images_folder}\n",
        "  !rm -r {images_folder}{temp_suffix}\n",
        "\n",
        "  print(f\"‚úÖ Se han eliminado {len(kys)} im√°genes no deseadas, quedan {len(os.listdir(train_data_dir))} im√°genes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sl4FD7Mz-uea"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 4Ô∏è‚É£ Descripciones de im√°genes\n",
        "#@markdown Usaremos inteligencia artificial para describir tus im√°genes, espec√≠ficamente [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2) en el caso de anime (etiquetas/tags) y [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) en el caso de fotorealismo (subt√≠tulos/captions).\n",
        "#@markdown Estas descripciones que van junto a tus im√°genes mejoran notablemente la calidad de tu Lora a la hora de entrenar. <p>\n",
        "metodo = \"Anime\" #@param [\"Anime\", \"Fotorealismo\"]\n",
        "method = metodo\n",
        "#@markdown **Anime:** El umbral es el nivel de certeza al que debe llegar la IA para asignar cada tag. Menor umbral = M√°s tags.\n",
        "umbral = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "tag_threshold = umbral\n",
        "#@markdown **Fotorealismo:** El m√≠nmimo y m√°ximo largo de cada subt√≠tulo (medido en tokens/palabras).\n",
        "largo_minimo = 10 #@param {type:\"number\"}\n",
        "caption_min = largo_minimo\n",
        "largo_maximo = 75 #@param {type:\"number\"}\n",
        "caption_max = largo_maximo\n",
        "\n",
        "%env PYTHONPATH=/env/python\n",
        "import os\n",
        "from google.colab import output as console\n",
        "from IPython import get_ipython\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "kohya = \"/content/kohya-trainer\"\n",
        "if not os.path.exists(kohya):\n",
        "  !git clone https://github.com/Linaqruf/kohya-trainer {kohya}\n",
        "  os.chdir(kohya)\n",
        "  !git reset --hard 86de685a8c37e60a610d08cbece3da6b3a553bc0\n",
        "  os.chdir(\"/content\")\n",
        "\n",
        "if \"Anime\" in method:\n",
        "  if \"step4a_installed_flag\" not in globals():\n",
        "    print(\"üè≠ Instalando...\\n\")\n",
        "    !pip install tensorflow==2.10.1 huggingface-hub==0.12.0 accelerate==0.15.0 transformers==4.26.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      console.clear()\n",
        "      step4a_installed_flag = True\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Iniciando programa...\\n\")\n",
        "\n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/tag_images_by_wd14_tagger.py \\\n",
        "    {images_folder} \\\n",
        "    --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 \\\n",
        "    --model_dir=/content \\\n",
        "    --thresh={tag_threshold} \\\n",
        "    --batch_size=8 \\\n",
        "    --caption_extension=.txt \\\n",
        "    --force_download\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    print(\"removing underscores...\")\n",
        "    from collections import Counter\n",
        "    top_tags = Counter()\n",
        "    for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        tags = [t.strip() for t in f.read().split(\",\")]\n",
        "        tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
        "      top_tags.update(tags)\n",
        "      with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "        f.write(\", \".join(tags))\n",
        "\n",
        "    %env PYTHONPATH=/env/python\n",
        "    console.clear()\n",
        "    print(f\"üìä Finalizado. Aqu√≠ est√°n las 50 tags m√°s comunes en tus im√°genes:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "    \n",
        "else: # Photorealism\n",
        "  if \"step4b_installed_flag\" not in globals():\n",
        "    print(\"üè≠ Instalando...\\n\")\n",
        "    !pip install timm==0.6.12 fairscale==0.4.13 transformers==4.26.0 requests==2.28.2 accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6\n",
        "    if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "      console.clear()\n",
        "      step4b_installed_flag = True\n",
        "\n",
        "  print(\"üö∂‚Äç‚ôÇÔ∏è Iniciando programa...\\n\")\n",
        "\n",
        "  os.chdir(kohya)\n",
        "  %env PYTHONPATH={kohya}\n",
        "  !python {kohya}/finetune/make_captions.py \\\n",
        "    {images_folder} \\\n",
        "    --beam_search \\\n",
        "    --max_data_loader_n_workers=2 \\\n",
        "    --batch_size=8 \\\n",
        "    --min_length={caption_min} \\\n",
        "    --max_length={caption_max} \\\n",
        "    --caption_extension=.txt\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    import random\n",
        "    captions = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    os.chdir(\"/content\")\n",
        "    %env PYTHONPATH=/env/python\n",
        "    console.clear()\n",
        "    print(f\"üìä Finalizado. Aqu√≠ hay {len(sample)} ejemplos de subt√≠tulos en tus im√°genes:\")\n",
        "    print(\"\".join(sample))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBFik7accyDz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#@markdown ### 5Ô∏è‚É£ Filtra tus tags\n",
        "#@markdown Puedes hacer modificaciones en las tags de tus im√°genes cuantas veces quieras. <p>\n",
        "\n",
        "#@markdown A√±adir una palabra de activaci√≥n a tu Lora, √∫til para mejorar el entrenamiento y usarlo en tus prompts. En el entrenamiento debes poner `keep_tokens` igual a 1.<p>\n",
        "#@markdown Si quitas tags comunes como el color de pelo/ojos √©stas ser√°n \"absorbidas\" por tu palabra de activaci√≥n.\n",
        "palabra_de_activacion = \"\" #@param {type:\"string\"}\n",
        "global_activation_tag = palabra_de_activacion\n",
        "quitar_tags = \"virtual youtuber\" #@param {type:\"string\"}\n",
        "remove_tags = quitar_tags\n",
        "#@markdown <p>&nbsp;<p> En esta zona avanzada puedes realizar reemplazos o combinaciones de tags para as√≠ mejorar su calidad. Puedes reemplazar 1 tag por varias, o varias por 1, o una por otra, etc. Tambi√©n puedes a√±adir palabras de activaci√≥n espec√≠ficas.\n",
        "buscar_tags = \"\" #@param {type:\"string\"}\n",
        "search_tags = buscar_tags\n",
        "reemplazar_con = \"\" #@param {type:\"string\"}\n",
        "replace_with = reemplazar_con\n",
        "modo_de_busqueda = \"OR (puede tener cualquiera)\" #@param [\"OR (puede tener cualquiera)\", \"AND (debe tener todo)\"]\n",
        "search_mode = modo_de_busqueda\n",
        "tag_nueva_se_convierte_en_palabra_de_activacion = False #@param {type:\"boolean\"}\n",
        "new_becomes_activation_tag = tag_nueva_se_convierte_en_palabra_de_activacion\n",
        "#@markdown Estas pueden ser √∫tiles a veces. Ten cuidado, pueden quitar las palabras de activaci√≥n previas.\n",
        "ordenar_alfabeticamente = False #@param {type:\"boolean\"}\n",
        "sort_alphabetically = ordenar_alfabeticamente\n",
        "quitar_duplicados = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = quitar_duplicados\n",
        "\n",
        "def split_tags(tagstr):\n",
        "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "  if remove_duplicates:\n",
        "    tags = list(set(tags))\n",
        "  if sort_alphabetically:\n",
        "    tags.sort()\n",
        "\n",
        "  for rem in remove_tags_list:\n",
        "    if rem in tags:\n",
        "      remove_count += 1\n",
        "      tags.remove(rem)\n",
        "\n",
        "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
        "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
        "    replace_count += 1\n",
        "    for rem in search_tags_list:\n",
        "      if rem in tags:\n",
        "        tags.remove(rem)\n",
        "    for add in replace_with_list:\n",
        "      if add not in tags:\n",
        "        tags.append(add)\n",
        "    for new in replace_new_list:\n",
        "      if new_becomes_activation_tag:\n",
        "        if new in tags:\n",
        "          tags.remove(new)\n",
        "        tags.insert(0, new)\n",
        "      else:\n",
        "        if new not in tags:\n",
        "          tags.append(new)\n",
        "\n",
        "  for act in activation_tag_list:\n",
        "    if act in tags:\n",
        "      tags.remove(act)\n",
        "    tags.insert(0, act)\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "    f.write(\", \".join(tags))\n",
        "\n",
        "if remove_tags:\n",
        "  print(f\"\\nüöÆ Se han quitado {remove_count} tags.\")\n",
        "if search_tags:\n",
        "  print(f\"\\nüí´ Se han hecho {replace_count} reemplazos.\")\n",
        "print(\"\\n‚úÖ ¬°Listo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HuJB7BGAyZCw"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 6Ô∏è‚É£  Listo\n",
        "#@markdown Ahora debes estar listo para [entrenar tu Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb).\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"ü¶Ä [Click aqu√≠ para abrir el colab de entrenamiento](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) \"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDB9GXRONfiU"
      },
      "source": [
        "## *Ô∏è‚É£ Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xEsqOglcc6hA"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìà Analizar tags\n",
        "#@markdown Volver a ver las tags m√°s comunes en tus im√°genes.\n",
        "ver_top = 200 #@param {type:\"number\"}\n",
        "show_top_tags = ver_top\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(train_data_dir) if f.lower().endswith(\".txt\")]:\n",
        "  with open(os.path.join(train_data_dir, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"üìä Tus {show_top_tags} tags m√°s comunes:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hcAHDi3zPjtg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Extraer datos\n",
        "#@markdown Es lento subir muchos archivos peque√±os, si quieres puedes subir un zip y extraerlo aqu√≠.\n",
        "zip = \"/content/drive/MyDrive/lora_training/datasets/warrior.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/lora_training/datasets/\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7AdGcZRyPmtm"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Contar archivos\n",
        "#@markdown Google Drive hace imposible contar los archivos en una carpeta, por lo que aqu√≠ puedes ver la cantidad de archivos en carpetas y subcarpetas.\n",
        "carpeta = \"/content/drive/MyDrive/lora_training/datasets\" #@param {type:\"string\"}\n",
        "folder = carpeta\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Conectando a Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder)):\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images and not captions and not others \\\n",
        "                    else f\"{images:>4} images | {captions:>4} text files | {others:>4} other files\"\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l0tzRu6xBqj9"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üöÆ Limpiar carpeta\n",
        "#@markdown Cuidado, borra todos los archivos que no sean im√°genes de la carpeta del proyecto.\n",
        "\n",
        "!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
